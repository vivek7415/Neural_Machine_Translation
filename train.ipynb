{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXvlB7Pu97B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import unicodedata\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAi5Frlm97B_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "  w = w.strip()\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV5DJMDA97CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiAlnWqZ97CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path = os.path.abspath('.')+'/spa-eng/spa.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0CdLWn--p84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eb35c9cc-9ecf-4331-c84e-8a59ff2d3ee0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L_h63ychpj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = os.path.abspath('.')+'/drive/My Drive/spa.txt'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Jz_2SfwJ97CG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2fc9111c-3212-402c-9efb-0c5b118cee96"
      },
      "source": [
        "en, sp, _= create_dataset(path, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-O7zlM3gvtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pnpLvcCBJNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bae2a94-60cb-4a62-e2de-30c9400688a2"
      },
      "source": [
        "len(en)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_gYU2P-97CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvTZInjo97CL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang, _ = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u4NtaFC97CN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang_tok, targ_lang_tok = load_dataset(path, num_examples)\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HaUdvP5o97CQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82f66b3d-d435-4770-c80d-b03cfe076b9d"
      },
      "source": [
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZkU8Ym297CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Sg1JHMkI97CU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "1e534ca3-cb0c-4809-8f9e-f213054789be"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang_tok, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang_tok, target_tensor_train[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "35 ----> tengo\n",
            "11 ----> que\n",
            "459 ----> volver\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> i\n",
            "59 ----> ve\n",
            "77 ----> got\n",
            "15 ----> to\n",
            "35 ----> go\n",
            "90 ----> back\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vaU7uUx97CX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08bdfd6b-6aa7-491d-fad9-080818ef1b15"
      },
      "source": [
        "target_tensor.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Vv5Yj597CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang_tok.word_index) + 1\n",
        "vocab_tar_size = len(targ_lang_tok.word_index)+ 1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "xl8CuOzD97Cc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18cde0f4-5805-410e-9e39-87b437ddbfbb"
      },
      "source": [
        "print(next(iter(dataset)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(64, 16), dtype=int32, numpy=\n",
            "array([[   1,   36,   38, ...,    0,    0,    0],\n",
            "       [   1,   30,    7, ...,    0,    0,    0],\n",
            "       [   1,   58, 2384, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   1,   32, 3288, ...,    0,    0,    0],\n",
            "       [   1,   25,   47, ...,    0,    0,    0],\n",
            "       [   1,   27,    7, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(64, 11), dtype=int32, numpy=\n",
            "array([[   1,    4,   66,   49,  775,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   20,    8,   49,  583,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   28,  125,  224,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    7,    8,   10, 3598,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   14,   11,  630,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,   53,  206,   42,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,  197,   11,   33,  595,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   17,   91,  557,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    4,   34, 1746,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,   27,   12,  510,  122,   83,    3,    2,    0,    0,    0],\n",
            "       [   1,    4,   16,  113,   15,  246,    9,    3,    2,    0,    0],\n",
            "       [   1,    7,   58,  229,  341,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    9,   26,  580,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    9,   11,   33,  495,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    7,  442,  735,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    4,   34,   30,  405,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    4,   66,  139,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    7,  499,   15,  145,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    7,    8, 4559, 2756,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    8,   55,  457,  204,    6,    2,    0,    0,    0,    0],\n",
            "       [   1,    4,  538,  838,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    5,   91,   36,   10, 1407,    3,    2,    0,    0,    0],\n",
            "       [   1,   14,  137, 2954,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    4,  725,    9,   26,    7,    3,    2,    0,    0,    0],\n",
            "       [   1,   67,   25,   13, 1042,    6,    2,    0,    0,    0,    0],\n",
            "       [   1,  603,   17,  470,    6,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    4,   29,   10,  405,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    4,  189,   21,  853,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   78,   40,    5,  287,    6,    2,    0,    0,    0,    0],\n",
            "       [   1,  206,   42,   10, 1722,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   22,    5,   44,   10,  829,    6,    2,    0,    0,    0],\n",
            "       [   1,  936,  522,    3,    2,    0,    0,    0,    0,    0,    0],\n",
            "       [   1,    4,  174,   34,  142,  772,    3,    2,    0,    0,    0],\n",
            "       [   1,  538,   20,    3,    2,    0,    0,    0,    0,    0,    0],\n",
            "       [   1,    7,   77,   10,  754,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    7,   11,  885,  209, 2799,    3,    2,    0,    0,    0],\n",
            "       [   1,    9,   11,   10, 1984,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,  559,   13, 1830,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    7,    8,  983,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,   40,    5,   68,   19,    6,    2,    0,    0,    0,    0],\n",
            "       [   1,    9,   11, 1288,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,  403,   25,   33, 1178,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    7,  220,  172,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,   14,   26,  469,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    5,   25, 2828,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    8,   55,   99,    6,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,   62,   27,   12,   87,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   40,   14,   35,   55,    6,    2,    0,    0,    0,    0],\n",
            "       [   1,    4,   68,  117,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,   29,   10,  361,   82,   18,    3,    2,    0,    0,    0],\n",
            "       [   1,    4,   66,   36,   13,  176,    3,    2,    0,    0,    0],\n",
            "       [   1,   87, 3563,  153,   37,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    4,   29,   15,   35,   15,  240,    3,    2,    0,    0],\n",
            "       [   1,    7,  230,  170, 3588,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   47,   18,  267,    9,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    7,   24,   12,  318,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,    7,  230,   63,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    9,   11,  212,   65,    3,    2,    0,    0,    0,    0],\n",
            "       [   1,   76,    5,   35,   50,   81,    6,    2,    0,    0,    0],\n",
            "       [   1, 2248,   13, 1927,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    4, 2596,   45,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1, 2298,  103, 1043,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,    4,   26,  215,    3,    2,    0,    0,    0,    0,    0],\n",
            "       [   1,   19,   11,  884,   37,    2,    0,    0,    0,    0,    0]],\n",
            "      dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "qxRBhWnU97Ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d6415b82-0a08-460f-d3a2-7195a1cd6581"
      },
      "source": [
        "x = tf.data.Dataset.from_tensor_slices(([1, 2, 3,4],[5,6,7,8])).shuffle(6)\n",
        "list(x.as_numpy_iterator())\n",
        "x = x.batch(3)\n",
        "list(x.as_numpy_iterator())\n",
        "# dataset = dataset.enumerate(start=5)\n",
        "# for element in dataset.as_numpy_iterator():\n",
        "#   print(element)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 3, 2], dtype=int32), array([5, 7, 6], dtype=int32)),\n",
              " (array([4], dtype=int32), array([8], dtype=int32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "3yatlJDm97Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(next(iter(dataset)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00Ryc7Xo97Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "        return_sequences=True,\n",
        "        return_state=True,\n",
        "        recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g53wBy_f97Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_hidden = encoder.initialize_hidden_state()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QkEZ8zb97Co",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c001acf8-6053-4648-bacb-0d338c7747df"
      },
      "source": [
        "sample_hidden.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5T0vx6N97Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX7LX0S997Ct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "358640ce-0326-4ee4-c019-8488204f7a18"
      },
      "source": [
        "print('Encoder output shape: batch size, sequence length, units {}'.format(sample_output.shape))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: batch size, sequence length, units (64, 16, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f8Ebcuw__4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad7aaf10-0e1c-4119-db19-6069674d52e0"
      },
      "source": [
        "print('Encoder Hidden state: batch_size, units {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder Hidden state: batch_size, units (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDbbpkRoA0hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query,1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    context_vector = attention_weights * values\n",
        "\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVOzgQjJy7wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f6c9e984-140d-4113-8d9d-f6c1de40c3bb"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch_size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_lengths) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch_size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_lengths) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoHvgYDmU_S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "    \n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector,1), x], axis=-1)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBVyEPtSicdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d1f0c78-249b-4917-cb48-a43618c58326"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
        "\n",
        "print('decoder output shape: (batch_size, vocab_size) {}'.format(sample_decoder_output.shape))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decoder output shape: (batch_size, vocab_size) (64, 4817)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd_T4QZDlwb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real,0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53OV8g1fwsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = os.path.abspath('.')+\"/drive/My Drive/training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pKQdiIyiYtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "570a3b2b-a216-4a2e-d800-82d8f41b92b2"
      },
      "source": [
        "targ_lang_tok.word_index['<start>']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PnZz_yohOWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss=0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tok.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss/ int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyHCeJgAlVN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69470460-a322-43dc-8ad0-31870387e83e"
      },
      "source": [
        "for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "  print(batch)\n",
        "  print(inp)\n",
        "  print(targ)\n",
        "  break"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "tf.Tensor(\n",
            "[[   1    5   89 ...    0    0    0]\n",
            " [   1   23  133 ...    0    0    0]\n",
            " [   1 2181   14 ...    0    0    0]\n",
            " ...\n",
            " [   1    5   29 ...    0    0    0]\n",
            " [   1    8   12 ...    0    0    0]\n",
            " [   1   14  372 ...    0    0    0]], shape=(64, 16), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[   1    8  446   55    6    2    0    0    0    0    0]\n",
            " [   1    4   66  459   61  121    3    2    0    0    0]\n",
            " [   1  107  653    3    2    0    0    0    0    0    0]\n",
            " [   1   27   12   88   90    3    2    0    0    0    0]\n",
            " [   1   87 1634   18   37    2    0    0    0    0    0]\n",
            " [   1   17   72    9   39    3    2    0    0    0    0]\n",
            " [   1   54  598    5    6    2    0    0    0    0    0]\n",
            " [   1    4  325    7   15   52    3    2    0    0    0]\n",
            " [   1   20   93   12   56 1753    3    2    0    0    0]\n",
            " [   1  372    8   30  397    6    2    0    0    0    0]\n",
            " [   1   32   11   13 2754    6    2    0    0    0    0]\n",
            " [   1    8   19  388    6    2    0    0    0    0    0]\n",
            " [   1   13   84    8  587    3    2    0    0    0    0]\n",
            " [   1  180   13 3349    3    2    0    0    0    0    0]\n",
            " [   1 1809   24  250    3    2    0    0    0    0    0]\n",
            " [   1    4  141   90   89  161    3    2    0    0    0]\n",
            " [   1    4  116 1047  158    3    2    0    0    0    0]\n",
            " [   1   17   23   69 2125    3    2    0    0    0    0]\n",
            " [   1   20    8   49  752    3    2    0    0    0    0]\n",
            " [   1    4   57  661 1773    3    2    0    0    0    0]\n",
            " [   1   20    8   70 1622    3    2    0    0    0    0]\n",
            " [   1    4   59  395    9    3    2    0    0    0    0]\n",
            " [   1    5   24  144    9   55    3    2    0    0    0]\n",
            " [   1    4   24  123   56    5    3    2    0    0    0]\n",
            " [   1  132   14  138  434    6    2    0    0    0    0]\n",
            " [   1    4   16 2328  326    3    2    0    0    0    0]\n",
            " [   1   47   11   35   15   10  763    3    2    0    0]\n",
            " [   1   13 2733    8 2342    3    2    0    0    0    0]\n",
            " [   1   54  286  419    6    2    0    0    0    0    0]\n",
            " [   1  465    7    8  276    3    2    0    0    0    0]\n",
            " [   1    5   25   13  284    3    2    0    0    0    0]\n",
            " [   1    4   59  351  237 1069    3    2    0    0    0]\n",
            " [   1   13  210    8  334    3    2    0    0    0    0]\n",
            " [   1    8   31   30  447    6    2    0    0    0    0]\n",
            " [   1   27   12 2575   18    3    2    0    0    0    0]\n",
            " [   1   17  239   78    3    2    0    0    0    0    0]\n",
            " [   1   71  106  363    3    2    0    0    0    0    0]\n",
            " [   1    4   38   35   42   21  517    3    2    0    0]\n",
            " [   1  428   36   13 3863    3    2    0    0    0    0]\n",
            " [   1    7   58  459  341    3    2    0    0    0    0]\n",
            " [   1    9   11   10  243    3    2    0    0    0    0]\n",
            " [   1   60  114  170   55    3    2    0    0    0    0]\n",
            " [   1   14  108   41  192 2253    3    2    0    0    0]\n",
            " [   1    9   11   21  438   99  131    3    2    0    0]\n",
            " [   1    4   72    5   86  165    3    2    0    0    0]\n",
            " [   1    4   95   74  126    3    2    0    0    0    0]\n",
            " [   1    4   16   10  354    3    2    0    0    0    0]\n",
            " [   1  128    9   36  434    3    2    0    0    0    0]\n",
            " [   1    5   88 1013    3    2    0    0    0    0    0]\n",
            " [   1   28   23   21  264    3    2    0    0    0    0]\n",
            " [   1   27   12  415   21 1041    3    2    0    0    0]\n",
            " [   1    4 1101   54   58   52    3    2    0    0    0]\n",
            " [   1    7  356    3    2    0    0    0    0    0    0]\n",
            " [   1 3936    8   10 1261    3    2    0    0    0    0]\n",
            " [   1  686  294    9    3    2    0    0    0    0    0]\n",
            " [   1   88   90   37    2    0    0    0    0    0    0]\n",
            " [   1   19   11   10  357    3    2    0    0    0    0]\n",
            " [   1    4   38   98   20   15    7    3    2    0    0]\n",
            " [   1    4  256   10  204 2305    3    2    0    0    0]\n",
            " [   1    4  174  246   19    3    2    0    0    0    0]\n",
            " [   1   51  430  382  230    6    2    0    0    0    0]\n",
            " [   1   22    5   34  434    6    2    0    0    0    0]\n",
            " [   1   27   12  106   18  455    3    2    0    0    0]\n",
            " [   1  382   25   86  276    3    2    0    0    0    0]], shape=(64, 11), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqr__cDhkze0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96a7bbb7-3105-4d05-9fed-ec5ad5f03c5c"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1, batch, batch_loss.numpy()))\n",
        "\n",
        "  if (epoch + 1) % 2 ==0:\n",
        "    checkpoint.save(file_prefix= checkpoint_prefix)\n",
        "  \n",
        "  print('Epoch {}, Loss {}'.format(epoch+1, total_loss/steps_per_epoch))\n",
        "\n",
        "  print('Time taken for 1 epoch {} sec \\n'.format(time.time() - start))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.4089\n",
            "Epoch 1 Batch 100 Loss 2.1233\n",
            "Epoch 1 Batch 200 Loss 1.8076\n",
            "Epoch 1 Batch 300 Loss 1.6243\n",
            "Epoch 1, Loss 2.010434150695801\n",
            "Time taken for 1 epoch 43.3237361907959 sec \n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5292\n",
            "Epoch 2 Batch 100 Loss 1.4762\n",
            "Epoch 2 Batch 200 Loss 1.3745\n",
            "Epoch 2 Batch 300 Loss 1.2801\n",
            "Epoch 2, Loss 1.350333571434021\n",
            "Time taken for 1 epoch 32.97252702713013 sec \n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0744\n",
            "Epoch 3 Batch 100 Loss 0.9748\n",
            "Epoch 3 Batch 200 Loss 0.8279\n",
            "Epoch 3 Batch 300 Loss 0.8952\n",
            "Epoch 3, Loss 0.9298057556152344\n",
            "Time taken for 1 epoch 32.10030651092529 sec \n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6432\n",
            "Epoch 4 Batch 100 Loss 0.6000\n",
            "Epoch 4 Batch 200 Loss 0.5846\n",
            "Epoch 4 Batch 300 Loss 0.6167\n",
            "Epoch 4, Loss 0.6250849962234497\n",
            "Time taken for 1 epoch 33.39562177658081 sec \n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4089\n",
            "Epoch 5 Batch 100 Loss 0.4123\n",
            "Epoch 5 Batch 200 Loss 0.3813\n",
            "Epoch 5 Batch 300 Loss 0.3902\n",
            "Epoch 5, Loss 0.4226386845111847\n",
            "Time taken for 1 epoch 31.902763605117798 sec \n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2716\n",
            "Epoch 6 Batch 100 Loss 0.2458\n",
            "Epoch 6 Batch 200 Loss 0.3016\n",
            "Epoch 6 Batch 300 Loss 0.3043\n",
            "Epoch 6, Loss 0.2937929928302765\n",
            "Time taken for 1 epoch 32.770418882369995 sec \n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2920\n",
            "Epoch 7 Batch 100 Loss 0.1949\n",
            "Epoch 7 Batch 200 Loss 0.2242\n",
            "Epoch 7 Batch 300 Loss 0.2655\n",
            "Epoch 7, Loss 0.20901694893836975\n",
            "Time taken for 1 epoch 31.969480276107788 sec \n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1183\n",
            "Epoch 8 Batch 100 Loss 0.1617\n",
            "Epoch 8 Batch 200 Loss 0.1565\n",
            "Epoch 8 Batch 300 Loss 0.1857\n",
            "Epoch 8, Loss 0.15616463124752045\n",
            "Time taken for 1 epoch 33.16887617111206 sec \n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1289\n",
            "Epoch 9 Batch 100 Loss 0.0765\n",
            "Epoch 9 Batch 200 Loss 0.1537\n",
            "Epoch 9 Batch 300 Loss 0.1237\n",
            "Epoch 9, Loss 0.12090999633073807\n",
            "Time taken for 1 epoch 31.87824273109436 sec \n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0755\n",
            "Epoch 10 Batch 100 Loss 0.0848\n",
            "Epoch 10 Batch 200 Loss 0.0794\n",
            "Epoch 10 Batch 300 Loss 0.1054\n",
            "Epoch 10, Loss 0.10035225749015808\n",
            "Time taken for 1 epoch 32.81871008872986 sec \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eZ0GJXnmzRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  inputs = [inp_lang_tok.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang_tok.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang_tok.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang_tok.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "    \n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6S7jmHXgnTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict = fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUBXrETOkr6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translations: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(\" \"), result.split(' '))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjLxp52omNyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62bffbc4-8b3d-40b1-fa8f-31b71e88424b"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f70d81eff28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SexUGDwmbDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "cafcc592-5808-48b3-b30f-3cf3e7da9c79"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translations: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuIPBvBVmmdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}